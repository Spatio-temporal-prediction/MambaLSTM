{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "def generate_road_similarity_graph(file_path, road_feature_cols, k, epsilon=1e-8):\n",
    "    \"\"\"\n",
    "    生成道路特征相似性图（Gf）的完整实现\n",
    "    :param file_path: 道路特征数据文件路径\n",
    "    :param road_feature_cols: 道路特征列名列表（需可统计为概率分布）\n",
    "    :param k: Top-k近邻数\n",
    "    :param epsilon: 避免零概率的小值\n",
    "    :return: 邻接矩阵 adj_matrix\n",
    "    \"\"\"\n",
    "    # --------------------------\n",
    "    # 步骤1: 数据预处理\n",
    "    # --------------------------\n",
    "    # 读取原始数据\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # 处理缺失值：假设-1为缺失值，替换为列中位数\n",
    "    for col in road_feature_cols:\n",
    "        median = data[col].median()\n",
    "        data[col] = data[col].replace(-1, median)\n",
    "    \n",
    "    # 转换为概率分布（总和归一化为1）\n",
    "    # 添加epsilon避免零值问题\n",
    "    data[road_feature_cols] = data[road_feature_cols] + epsilon\n",
    "    data[road_feature_cols] = data[road_feature_cols].div(data[road_feature_cols].sum(axis=1), axis=0)\n",
    "    \n",
    "    # --------------------------\n",
    "    # 步骤2: 计算JS散度相似性\n",
    "    # --------------------------\n",
    "    n_grids = len(data)\n",
    "    similarity_matrix = np.zeros((n_grids, n_grids))\n",
    "    \n",
    "    for i in range(n_grids):\n",
    "        p_i = data.iloc[i][road_feature_cols].values\n",
    "        for j in range(i+1, n_grids):\n",
    "            p_j = data.iloc[j][road_feature_cols].values\n",
    "            \n",
    "            # 计算JS散度（注意scipy的JS实现返回sqrt值）\n",
    "            js_divergence = jensenshannon(p_i, p_j) ** 2  # 需要平方获取实际JS值\n",
    "            similarity = 1 - js_divergence\n",
    "            \n",
    "            # 对称填充矩阵\n",
    "            similarity_matrix[i, j] = similarity\n",
    "            similarity_matrix[j, i] = similarity\n",
    "    \n",
    "    # --------------------------\n",
    "    # 步骤3: 构建Top-k邻接矩阵\n",
    "    # --------------------------\n",
    "    adj_matrix = np.zeros((n_grids, n_grids))\n",
    "    for i in range(n_grids):\n",
    "        # 获取相似性排序（降序）\n",
    "        sim_scores = similarity_matrix[i, :]\n",
    "        \n",
    "        # 排除自身（可选）\n",
    "        sim_scores[i] = 0\n",
    "        \n",
    "        # 选择Top-k索引\n",
    "        top_k_indices = np.argpartition(sim_scores, -k)[-k:]\n",
    "        \n",
    "        # 保留相似性权重\n",
    "        adj_matrix[i, top_k_indices] = sim_scores[top_k_indices]\n",
    "    \n",
    "    return adj_matrix\n",
    "\n",
    "\n",
    "# def generate_road_similarity_graph(file_path, road_feature_cols, k):\n",
    "#     # 读取数据\n",
    "#     data = pd.read_csv(file_path)\n",
    "\n",
    "#     # 替换-1为列的中位数\n",
    "#     for col in road_feature_cols:\n",
    "#         median = data[col].median()\n",
    "#         data[col] = data[col].replace(-1, median)\n",
    "\n",
    "#     # 标准化特征\n",
    "#     scaler = StandardScaler()\n",
    "#     data[road_feature_cols] = scaler.fit_transform(data[road_feature_cols])\n",
    "\n",
    "#     # 计算余弦相似度\n",
    "#     n_grids = len(data)\n",
    "#     similarity_matrix = np.zeros((n_grids, n_grids))\n",
    "\n",
    "#     for i in range(n_grids):\n",
    "#         for j in range(i + 1, n_grids):\n",
    "#             similarity = 1 - cosine(data.iloc[i][road_feature_cols], data.iloc[j][road_feature_cols])\n",
    "#             similarity_matrix[i, j] = similarity\n",
    "#             similarity_matrix[j, i] = similarity\n",
    "\n",
    "#     # 构建k近邻图\n",
    "#     adj_matrix = np.zeros((n_grids, n_grids))\n",
    "#     for i in range(n_grids):\n",
    "#         sim_scores = similarity_matrix[i, :]\n",
    "#         top_k_indices = sim_scores.argsort()[-k:][::-1]\n",
    "#         adj_matrix[i, top_k_indices] = sim_scores[top_k_indices]\n",
    "\n",
    "#     return adj_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "def generate_poi_similarity_graph(file_path, feature_cols, k):\n",
    "    # 读取数据\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # 处理POI数据：加1平滑，避免零概率\n",
    "    data[feature_cols] = (data[feature_cols] + 1).div((data[feature_cols] + 1).sum(axis=1), axis=0)\n",
    "\n",
    "    # 计算JS散度\n",
    "    n_grids = len(data)\n",
    "    distance_matrix = np.zeros((n_grids, n_grids))\n",
    "\n",
    "    for i in range(n_grids):\n",
    "        for j in range(i + 1, n_grids):\n",
    "            distance = jensenshannon(data.iloc[i][feature_cols], data.iloc[j][feature_cols])\n",
    "            distance_matrix[i, j] = distance\n",
    "            distance_matrix[j, i] = distance\n",
    "\n",
    "    # 将距离转化为相似度\n",
    "    similarity_matrix = 1 - distance_matrix\n",
    "    np.fill_diagonal(similarity_matrix, 0)  # 将对角线元素设为0，消除自环\n",
    "\n",
    "    # 构建k近邻图\n",
    "    adj_matrix = np.zeros((n_grids, n_grids))\n",
    "    for i in range(n_grids):\n",
    "        sim_scores = similarity_matrix[i, :]\n",
    "        top_k_indices = sim_scores.argsort()[-k:][::-1]\n",
    "        adj_matrix[i, top_k_indices] = sim_scores[top_k_indices]\n",
    "\n",
    "    return adj_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.metrics import dtw_path\n",
    "\n",
    "def generate_risk_similarity_graph(file_path, k):\n",
    "    # 读取事故风险数据\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # 提取网格编号和时间片段\n",
    "    grid_ids = data['grid_id'].unique()\n",
    "    time_slots = data['time_slot'].unique()\n",
    "\n",
    "    # 重塑数据为网格 x 时间片的矩阵\n",
    "    risk_matrix = data.pivot(index='grid_id', columns='time_slot', values='risk_label')\n",
    "\n",
    "    # 计算DTW距离\n",
    "    n_grids = len(grid_ids)\n",
    "    distance_matrix = np.zeros((n_grids, n_grids))\n",
    "\n",
    "    for i in range(n_grids):\n",
    "        for j in range(i + 1, n_grids):\n",
    "            series_i = risk_matrix.iloc[i].values\n",
    "            series_j = risk_matrix.iloc[j].values\n",
    "\n",
    "            # 计算DTW距离\n",
    "            _, distance = dtw_path(series_i, series_j)\n",
    "            distance_matrix[i, j] = distance\n",
    "            distance_matrix[j, i] = distance\n",
    "\n",
    "        print(f'{i + 1}/{n_grids}')\n",
    "\n",
    "    # 将距离转化为相似度\n",
    "    similarity_matrix = 1 / (1 + distance_matrix)\n",
    "    np.fill_diagonal(similarity_matrix, 0)  # 将对角线元素设为0，消除自环\n",
    "\n",
    "    # 构建k近邻图\n",
    "    adj_matrix = np.zeros((n_grids, n_grids))\n",
    "    for i in range(n_grids):\n",
    "        sim_scores = similarity_matrix[i, :]\n",
    "        top_k_indices = sim_scores.argsort()[-k:][::-1]\n",
    "        adj_matrix[i, top_k_indices] = sim_scores[top_k_indices]\n",
    "\n",
    "    return adj_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_multiple_samples(sample_files, k, names):\n",
    "    for file, name in zip(sample_files, names):\n",
    "        f1, f2 = file\n",
    "        # 生成道路相似度图\n",
    "        road_feature_cols = ['rating_min', 'rating_max', 'rating_mean', 'rating_median', 'road_density']\n",
    "        road_adj_matrix = generate_road_similarity_graph(f1, road_feature_cols, k)\n",
    "        np.save(f'/root/autodl-tmp/npy/new_road_adj_matrix_{name}.npy', road_adj_matrix)\n",
    "        print(\"生成道路相似度图\",name)\n",
    "\n",
    "        # 生成POI相似度图\n",
    "        feature_cols = [f'faci_dom_{i}_count' for i in range(1, 19)]\n",
    "        poi_adj_matrix = generate_poi_similarity_graph(f1, feature_cols, k)\n",
    "        np.save(f'/root/autodl-tmp/npy/new_poi_adj_matrix_{name}.npy', poi_adj_matrix)\n",
    "        print(\"生成POI相似度图\",name)\n",
    "\n",
    "        # 生成事故风险图\n",
    "        risk_adj_matrix = generate_risk_similarity_graph(f2, k)\n",
    "        np.save(f'/root/autodl-tmp/npy/new_risk_adj_matrix_{name}.npy', risk_adj_matrix)\n",
    "        print(\"生成事故风险图\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成道路相似度图 c\n",
      "生成POI相似度图 c\n",
      "1/65\n",
      "2/65\n",
      "3/65\n",
      "4/65\n",
      "5/65\n",
      "6/65\n",
      "7/65\n",
      "8/65\n",
      "9/65\n",
      "10/65\n",
      "11/65\n",
      "12/65\n",
      "13/65\n",
      "14/65\n",
      "15/65\n",
      "16/65\n",
      "17/65\n",
      "18/65\n",
      "19/65\n",
      "20/65\n",
      "21/65\n",
      "22/65\n",
      "23/65\n",
      "24/65\n",
      "25/65\n",
      "26/65\n",
      "27/65\n",
      "28/65\n",
      "29/65\n",
      "30/65\n",
      "31/65\n",
      "32/65\n",
      "33/65\n",
      "34/65\n",
      "35/65\n",
      "36/65\n",
      "37/65\n",
      "38/65\n",
      "39/65\n",
      "40/65\n",
      "41/65\n",
      "42/65\n",
      "43/65\n",
      "44/65\n",
      "45/65\n",
      "46/65\n",
      "47/65\n",
      "48/65\n",
      "49/65\n",
      "50/65\n",
      "51/65\n",
      "52/65\n",
      "53/65\n",
      "54/65\n",
      "55/65\n",
      "56/65\n",
      "57/65\n",
      "58/65\n",
      "59/65\n",
      "60/65\n",
      "61/65\n",
      "62/65\n",
      "63/65\n",
      "64/65\n",
      "65/65\n",
      "生成事故风险图 c\n"
     ]
    }
   ],
   "source": [
    "sample_files = [('save/grid_data_c_1.csv', 'save/grid_data_c_2.csv')]\n",
    "sample_names = [ 'c']\n",
    "process_multiple_samples(sample_files, 8, sample_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_files = [('save/grid_data_f_1.csv', 'save/grid_data_f_2.csv'), ('save/grid_data_c_1.csv', 'save/grid_data_c_2.csv')]\n",
    "# sample_names = ['f', 'c']\n",
    "# process_multiple_samples(sample_files, 8, sample_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_files = [('save/grid_data_f_1.csv', 'save/grid_data_f_3.csv'), ('save/grid_data_c_1.csv', 'save/grid_data_c_3.csv')]\n",
    "# sample_names = ['f', 'c']\n",
    "# process_multiple_samples(sample_files, 8, sample_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
